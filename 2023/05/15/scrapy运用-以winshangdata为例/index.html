<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>scrapy运用-以winshangdata为例 | cthousand</title>
  <meta name="keywords" content=" web爬虫 , scrapy ">
  <meta name="description" content="scrapy运用-以winshangdata为例 | cthousand">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="目标地址：https:&#x2F;&#x2F;zc-paimai.taobao.com&#x2F;需求：使用爬虫抓取淘宝法拍房数据，针对北上广三个城市进行全量采集，数据不低于500条字段：标题、价格、地区 思路前期工作定位接口 精简请求  一共4个参数需要逆向  参数逆向_m_h5_tk和_m_h5_tk_enccookie来源分为2种,后端返回与前端生成,先验证第一种。  很好,这说明两个参数都是后端返回的,逆向进度直接完成">
<meta property="og:type" content="article">
<meta property="og:title" content="阿里系sign参数逆向-以法拍网为例.md">
<meta property="og:url" content="http://example.com/2023/05/18/%E9%98%BF%E9%87%8C%E7%B3%BBsign%E5%8F%82%E6%95%B0%E9%80%86%E5%90%91-%E4%BB%A5%E6%B3%95%E6%8B%8D%E7%BD%91%E4%B8%BA%E4%BE%8B-md/index.html">
<meta property="og:site_name" content="cthousand">
<meta property="og:description" content="目标地址：https:&#x2F;&#x2F;zc-paimai.taobao.com&#x2F;需求：使用爬虫抓取淘宝法拍房数据，针对北上广三个城市进行全量采集，数据不低于500条字段：标题、价格、地区 思路前期工作定位接口 精简请求  一共4个参数需要逆向  参数逆向_m_h5_tk和_m_h5_tk_enccookie来源分为2种,后端返回与前端生成,先验证第一种。  很好,这说明两个参数都是后端返回的,逆向进度直接完成">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/d90496dce7af43e4b257c7879e3b39ec.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/021cef0798ec4838979d02378e4f98dc.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/1509546aae9a4876b7aa0ba14f9b842e.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/e68023039c834b268500c00f6758e06b.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/6526166cf51a4c32b8844f1d4539e01a.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/c97b6122ea2f43cc90fea37268a09c61.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/3d32e449fe7743de9378e4467907bed2.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/0c5ffb7dd8de4f8da839a4eff673346e.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/e8767cec49964c859beb2b29c48b9909.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/9db00e25dd9741b29f34b0c2b3776282.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/988d1e8eaff44bdfbb6ec8f3a6ecbb89.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/d9864f8da55a46258798862f8e249d39.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/c18ae30a56d148b49a0daed9b4b8e578.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/d7b8bae0fff04e999d16adc5153e7b74.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/d956d48106624c548923b4f7993e02d4.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/7cc46001e2494e129de2454d868a6b78.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/0c92de849a194f25b3f539aae512fcd7.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/a29a893a8f5a4cc28bbf68e07ef64c1a.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/d03c417d2fd2492ea5f403deb9df7f3d.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/abf42b1e567343449a2414c5009bb3b1.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/f2c445c087124b619adcc0b6cb13e233.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/e9a53afddf2f4d33a0efc171617d44d6.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/15d2b483a95c43f09b4b3eb3b6d6fa60.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/ec888458e3c7465daa30a2d895186471.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/3b55ac75bcec421cbd625b8cf80a6c4b.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="og:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/9ff1ab0025fa49feb1dcf9182a784968.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">
<meta property="article:published_time" content="2023-05-18T08:34:23.000Z">
<meta property="article:modified_time" content="2023-05-18T12:53:18.256Z">
<meta property="article:author" content="Cthousand">
<meta property="article:tag" content="web逆向">
<meta property="article:tag" content="阿里系">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230518/d90496dce7af43e4b257c7879e3b39ec.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg">


<link rel="icon" href="/img/avatar.jpg">

<link href="/css/style.css?v=1.1.0" rel="stylesheet">

<link href="/css/hl_theme/darcula.css?v=1.1.0" rel="stylesheet">

<link href="//cdn.jsdelivr.net/npm/animate.css@4.1.0/animate.min.css" rel="stylesheet">

<script src="//cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
<script src="/js/titleTip.js?v=1.1.0" ></script>

<script src="//cdn.jsdelivr.net/npm/highlightjs@9.16.2/highlight.pack.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script>



<script src="//cdn.jsdelivr.net/npm/jquery.cookie@1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.1.0" ></script>

<meta name="generator" content="Hexo 6.3.0"></head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="">
  <input class="theme_blog_path" value="">
  <input id="theme_shortcut" value="true" />
  <input id="theme_highlight_on" value="true" />
  <input id="theme_code_copy" value="true" />
</div>



<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/"
   class="avatar_target">
    <img class="avatar"
         src="/img/avatar.jpg"/>
</a>
<div class="author">
    <span>Cthousand</span>
</div>

<div class="icon">
    
        
            <a title="github"
               href="https://github.com/Cthousand"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-github"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="email"
               href="mailto:2454612285@qq.com"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-email"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="qq"
               href="http://wpa.qq.com/msgrd?v=3&uin=2454612285&site=qq&menu=yes"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-qq"></use>
                    </svg>
                
            </a>
        
    
</div>




<ul>
    <li>
        <div class="all active" data-rel="全部文章">全部文章
            
                <small>(4)</small>
            
        </div>
    </li>
    
        
            
                <li>
                    <div data-rel="爬虫">
                        
                        爬虫
                        <small>(3)</small>
                        
                    </div>
                    
                </li>
            
        
    
</ul>
<div class="left-bottom">
    <div class="menus">
        
            
            
            
    </div>
    <div>
        
        
    </div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="4">

<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="iconfont icon-left"></i>
    </div>
    <div class="friends-content">
        <ul>
            
            <li><a target="_blank" href="http://yelog.org/">叶落阁</a></li>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <div class="right-top">
        <div id="default-panel">
            <i class="iconfont icon-search" data-title="搜索 快捷键 i"></i>
            <div class="right-title">全部文章</div>
            <i class="iconfont icon-file-tree" data-title="切换到大纲视图 快捷键 w"></i>
        </div>
        <div id="search-panel">
            <i class="iconfont icon-left" data-title="返回"></i>
            <input id="local-search-input" autocomplete="off"/>
            <label class="border-line" for="input"></label>
            <i class="iconfont icon-case-sensitive" data-title="大小写敏感"></i>
            <i class="iconfont icon-tag" data-title="标签"></i>
        </div>
        <div id="outline-panel" style="display: none">
            <div class="right-title">大纲</div>
            <i class="iconfont icon-list" data-title="切换到文章列表"></i>
        </div>
    </div>

    <div class="tags-list">
    <input id="tag-search" />
    <div class="tag-wrapper">
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>阿里系</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>加速乐</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>cookie加密</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>scrapy</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>web逆向</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>web爬虫</a>
            </li>
        
    </div>

</div>

    
    <nav id="title-list-nav">
        
        
        <a  class="全部文章 爬虫 "
           href="/2023/05/18/%E9%98%BF%E9%87%8C%E7%B3%BBsign%E5%8F%82%E6%95%B0%E9%80%86%E5%90%91-%E4%BB%A5%E6%B3%95%E6%8B%8D%E7%BD%91%E4%B8%BA%E4%BE%8B-md/"
           data-tag="web逆向,阿里系"
           data-author="" >
            <span class="post-title" title="阿里系sign参数逆向-以法拍网为例.md">阿里系sign参数逆向-以法拍网为例.md</span>
            <span class="post-date" title="2023-05-18 16:34:23">2023/05/18</span>
        </a>
        
        
        <a  class="全部文章 爬虫 "
           href="/2023/05/17/cookie%E9%80%86%E5%90%91-%E4%BB%A5hefei%E4%B8%BA%E4%BE%8B/"
           data-tag="web爬虫,加速乐,cookie加密"
           data-author="" >
            <span class="post-title" title="cookie加密-以hefei为例">cookie加密-以hefei为例</span>
            <span class="post-date" title="2023-05-17 13:50:48">2023/05/17</span>
        </a>
        
        
        
        <a  class="全部文章 爬虫 "
           href="/2023/05/15/scrapy%E8%BF%90%E7%94%A8-%E4%BB%A5winshangdata%E4%B8%BA%E4%BE%8B/"
           data-tag="web爬虫,scrapy"
           data-author="" >
            <span class="post-title" title="scrapy运用-以winshangdata为例">scrapy运用-以winshangdata为例</span>
            <span class="post-date" title="2023-05-15 15:48:57">2023/05/15</span>
        </a>
        
        <div id="no-item-tips">

        </div>
    </nav>
    <div id="outline-list">
    </div>
</div>

    </div>
    <div class="hide-list">
        <div class="semicircle" data-title="切换全屏 快捷键 s">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div id="post">
    <div class="pjax">
        <article id="post-scrapy运用-以winshangdata为例" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">scrapy运用-以winshangdata为例</h1>
    
    <div class="article-meta">
        
        
        
        <span class="book">
            <i class="iconfont icon-category"></i>
            
            
            <a  data-rel="爬虫">爬虫</a>
            
        </span>
        
        
        <span class="tag">
            <i class="iconfont icon-tag"></i>
            
            <a class="color1">web爬虫</a>
            
            <a class="color2">scrapy</a>
            
        </span>
        
    </div>
    <div class="article-meta">
        
            发布时间 : <time class="date" title='最后更新: 2023-05-18 20:41:16'>2023-05-15 15:48</time>
        
    </div>
    <div class="article-meta">
        
        
        <span id="busuanzi_container_page_pv">
            阅读 :<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
        <span class="top-comment" title="跳转至评论区">
            <a href="#comments">
                评论 :<span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </a>
        </span>
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E7%9B%AE%E6%A0%87"><span class="toc-text">一、目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%80%9D%E8%B7%AF"><span class="toc-text">二、思路</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E4%BB%A3%E7%A0%81"><span class="toc-text">三、代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">总结</span></a></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="一、目标"><a href="#一、目标" class="headerlink" title="一、目标"></a>一、目标</h3><ol>
<li>地址：<a target="_blank" rel="noopener" href="http://www.winshangdata.com/brandList">http://www.winshangdata.com/brandList</a></li>
<li>需求：用scrapy框架采集本站数据，至少抓取5个分类，数据量要求5000以上</li>
<li>采集字段：标题、创建时间、开店方式、合作期限、面积要求</li>
</ol>
<h3 id="二、思路"><a href="#二、思路" class="headerlink" title="二、思路"></a>二、思路</h3><ol>
<li>通过F12抓包分析，发现<ol>
<li>其无加密防护</li>
<li>翻页参数在前一页的返回里</li>
<li>页面结构为列表页+详情页</li>
</ol>
</li>
<li>spider文件中重写start_requests方法，用5个分类构造5个初始Request对象,<br>回调为parse_index</li>
<li>parse_index中解析并构造详情页的Request对象，回调为parse_detail;<br>解析并构造下一页的列表页Requset对象，回调为parse_index</li>
<li>用pipeline中间件写mongodb保存类，用middleware写随机ua和代理</li>
</ol>
<div style="display: flex;justify-content:center" >
<img src="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230516/1d8e17dbec8c48d29d9f3b1a038707e6.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg" alt=""/>
<img src="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230516/21167986002049c7b3e5488dca21c46d.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg" alt=""/>
</div>

<h3 id="三、代码"><a href="#三、代码" class="headerlink" title="三、代码"></a>三、代码</h3><ol>
<li>spider</li>
</ol>
<pre><code class="python">import json

import scrapy
from jmespath import search
from tuling_test.items import TulingTestItem
from scrapy import cmdline


class WinshangdataSpider(scrapy.Spider):
    name = &quot;winshangdata&quot;
    allowed_domains = [&quot;www.winshangdata.com&quot;]

    def start_requests(self):
        for i in [&#39;餐饮&#39;, &#39;儿童亲子&#39;, &#39;文体娱&#39;, &#39;零售&#39;, &#39;生活服务&#39;]:
            headers = &#123;
                &quot;Content-Type&quot;: &quot;application/json;charset=UTF-8&quot;,
                &quot;Referer&quot;: &quot;http://www.winshangdata.com/brandList&quot;,
            &#125;
            url = &quot;http://www.winshangdata.com/wsapi/brand/list3_4&quot;
            data = &#123;
                &quot;isHaveLink&quot;: &quot;&quot;,
                &quot;isTuozhan&quot;: &quot;&quot;,
                &quot;pageNum&quot;: 1,
                &quot;pageSize&quot;: 60,
                &quot;pid&quot;: &quot;&quot;,
                &quot;qy_p&quot;: &quot;&quot;,
                &quot;qy_r&quot;: &quot;&quot;,
                &quot;xqMj&quot;: &quot;&quot;,
                &quot;ytlb1&quot;: i,
                &quot;ytlb2&quot;: &quot;&quot;
            &#125;
            yield scrapy.Request(url, method=&#39;POST&#39;, headers=headers, body=json.dumps(data), callback=self.parse_index,
                                 meta=&#123;&#39;sort&#39;: i&#125;)

    def parse_index(self, response):
        # 拿到详情页url,构造详情页请求
        # 拿到下一页，构造列表页请求
        data = response.json()
        items = search(&#39;data.list&#39;, data)
        for item in items:
            brandId = search(&#39;brandId&#39;, item)
            url = &#39;https://www.winshangdata.com&#39; + f&#39;/brandDetail?brandId=&#123;brandId&#125;&#39;
            yield scrapy.Request(url, callback=self.parse_detail, meta=&#123;&#39;sort&#39;: response.meta[&#39;sort&#39;]&#125;)
        nex_page = search(&#39;data.nextPage&#39;, data)
        if nex_page &lt; 3:
            headers = &#123;
                &quot;Content-Type&quot;: &quot;application/json;charset=UTF-8&quot;,
                &quot;Referer&quot;: &quot;http://www.winshangdata.com/brandList&quot;,
            &#125;
            url = &quot;http://www.winshangdata.com/wsapi/brand/list3_4&quot;
            data = &#123;
                &quot;isHaveLink&quot;: &quot;&quot;,
                &quot;isTuozhan&quot;: &quot;&quot;,
                &quot;isXxPp&quot;: &quot;&quot;,
                &quot;kdfs&quot;: &quot;&quot;,
                &quot;key&quot;: &quot;&quot;,
                &quot;orderBy&quot;: &quot;1&quot;,
                &quot;pageNum&quot;: nex_page,
                &quot;pageSize&quot;: 60,
                &quot;pid&quot;: &quot;&quot;,
                &quot;qy_p&quot;: &quot;&quot;,
                &quot;qy_r&quot;: &quot;&quot;,
                &quot;xqMj&quot;: &quot;&quot;,
                &quot;ytlb1&quot;: response.meta[&#39;sort&#39;],
                &quot;ytlb2&quot;: &quot;&quot;
            &#125;
            yield scrapy.Request(url, method=&#39;POST&#39;, headers=headers, body=json.dumps(data), callback=self.parse_index,
                                 meta=&#123;&#39;sort&#39;: response.meta[&#39;sort&#39;]&#125;)

    def parse_detail(self, response):
        # 从列表页中解析出所需要的数据
        item = TulingTestItem()
        item[&#39;sort&#39;] = response.meta[&#39;sort&#39;]
        item[&#39;title&#39;] = response.xpath(&#39;//h1[@class=&quot;detail-one-tit&quot;]/text()&#39;).extract_first().strip()
        item[&#39;create_data&#39;] = response.xpath(
            &#39;//span[@class=&quot;detail-option-name&quot; and contains(text(),&quot;创立时间&quot;)]/following-sibling::span/text()&#39;).extract_first()
        item[&#39;shop_mode&#39;] = response.xpath(
            &#39;//span[@class=&quot;detail-option-name&quot; and contains(text(),&quot;开店方式&quot;)]/following-sibling::span/text()&#39;).extract_first()
        item[&#39;cooperation_term&#39;] = response.xpath(
            &#39;//span[@class=&quot;detail-option-name&quot; and contains(text(),&quot;合作期限&quot;)]/following-sibling::span/text()&#39;).extract_first()
        item[&#39;area_req&#39;] = response.xpath(
            &#39;//span[@class=&quot;detail-option-name&quot; and contains(text(),&quot;面积要求&quot;)]/following-sibling::span/text()&#39;).extract_first()
        yield item


if __name__ == &#39;__main__&#39;:
    cmdline.execute(&quot;scrapy crawl winshangdata&quot;.split())
</code></pre>
<ol start="2">
<li>pipeline</li>
</ol>
<pre><code class="python">import pymongo


class MongoDBPipeline:
    def __init__(self, mongo_host, mongo_port, mongo_dbname, mongo_docname):
        self.mongo_host = mongo_host
        self.mongo_port = mongo_port
        self.mongo_dbname = mongo_dbname
        self.mongo_docname = mongo_docname

    @classmethod
    def from_crawler(cls, crawler):
        host = crawler.settings.get(&#39;MONGODB_HOST&#39;)
        port = crawler.settings.get(&#39;MONGODB_PORT&#39;)
        dbname = crawler.settings.get(&#39;MONGODB_DBNAME&#39;)
        docname = crawler.settings.get(&#39;MONGODB_DOCNAME&#39;)

        return cls(host, port, dbname, docname)

    def open_spider(self, spider):
        self.client = pymongo.MongoClient(self.mongo_host, self.mongo_port)
        self.db = self.client[self.mongo_dbname]

    def close_spider(self, spider):
        self.client.close()

    def process_item(self, item, spider):
        self.db[self.mongo_docname].insert_one(dict(item))
        self.db[self.mongo_docname].update_one(&#123;
            &#39;sort&#39;: item[&#39;sort&#39;],
            &#39;title&#39;: item[&#39;title&#39;]
        &#125;, &#123;&#39;$set&#39;: dict(item)&#125;, True)
        return item
</code></pre>
<ol start="3">
<li>middleware</li>
</ol>
<pre><code class="python">import random


class RandomUserAgentMiddleware:
    def __init__(self, agents):
        self.agents = agents

    @classmethod
    def from_crawler(cls, crawler):
        return cls(crawler.settings.getlist(&#39;USER_AGENTS&#39;))

    def process_request(self, request, spider):
        request.headers[&#39;User-Agent&#39;] = random.choice(self.agents)


class RandomProxyMiddleware:
    def __init__(self, proxy_pool):
        self.proxy_pool = proxy_pool

    @classmethod
    def from_crawler(cls, crawler):
        return cls(crawler.settings.getlist(&#39;PROXY_POOL&#39;))

    def process_request(self, request, spider):
        request.meta[&#39;proxy&#39;] = random.choice(self.proxy_pool)
</code></pre>
<ol start="4">
<li>结果</li>
</ol>
<p><img src="https://cthousand-pic-save.oss-cn-hangzhou.aliyuncs.com/images/20230516/a06acc2c5a8e4002bf54a4bb531e631c.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_100/format,jpg" alt="结果"></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本案列考察了scrapy中:</p>
<ol>
<li>嵌套页面的处理</li>
<li>pipeline与mongodb数据保存</li>
<li>middleware随机更换ua和proxy</li>
</ol>

      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。可以在下面评论区评论，也可以邮件至 2454612285@qq.com </span>
    </div>
</article>





    <div id="comments"></div>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

<script type="text/javascript">
    $.getScript('/js/gitalk.js', function () {
        var gitalk = new Gitalk({
            clientID: '214c5cb5f884cc696370',
            clientSecret: 'd8cc5414db1e24724d504f4157d453a7143835c8',
            repo: 'cthousand.github.io',
            owner: 'Cthousand',
            admin: ['cthousand'],
            id: decodeURI(location.pathname),
            distractionFreeMode: 'true',
            language: 'zh-CN',
            perPage: parseInt('10',10)
        })
        gitalk.render('comments')
    })
</script>




    




    </div>
    <div class="copyright">
        <p class="footer-entry">
    ©2021-2025 Yelog
</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full" data-title="切换全屏 快捷键 s"><span class="min "></span></button>
<a class="" id="rocket" ></a>

    </div>
</div>

</body>
<script src="/js/jquery.pjax.js?v=1.1.0" ></script>

<script src="/js/script.js?v=1.1.0" ></script>
<script>
    var img_resize = 'default';
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $("#post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        

        /*高亮代码块行号*/
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    

</script>

<!--加入行号的高亮代码块样式-->

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    

    
</style>







</html>
